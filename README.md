# Hybrid Data Engineering + Data Science Learning Path
### Moving away from Datacamp's approach, and into something more unique to me.

> **My prompt to GenAI:** Provide me with a learning journey which is self-directed and structured to explore various disciplines within data - from engineering to science. It should be designed to build my confidence, fluency, and hands-on capability through a practical, project-based approach without being tied to industry pressure or trends. I want to understand how to both handle data and discover with it.

---

## ğŸ§­ Learning Journey Structure 
| Module | Focus Area                          |
|--------|-------------------------------------|
| 1      | Data Engineering & Foundations      |
| 2      | Pipelines & Orchestration           |
| 3      | Analytics Engineering & Warehousing |
| 4      | Core Data Science & ML Principles   |
| 5      | Deployment, DevOps & Capstone       |

---

## ğŸ“ Initial Repo Structure
```
hybrid-data-engineering-datascience/
â”œâ”€â”€ Module_1_Foundations/
â”‚   â”œâ”€â”€ notes.md
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ exercises/
â”‚   â””â”€â”€ project/
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ csv_to_parquet_to_s3.py
â”œâ”€â”€ Module_2_Pipelines/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ airflow_etl_dag.py
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ Module_3_Analytics_Eng/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ dbt_project/
â”‚   â””â”€â”€ bigquery_setup.md
â”œâ”€â”€ Module_4_DataScience_ML/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ core_concepts_notes.md
â”‚   â”œâ”€â”€ from_scratch_implementations/
â”‚   â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”‚   â”œâ”€â”€ k_nearest_neighbors.py
â”‚   â”‚   â””â”€â”€ decision_trees.py
â”‚   â””â”€â”€ ml_practice_notebooks/
â”œâ”€â”€ Module_5_Deployment/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ dockerfile
â”‚   â”œâ”€â”€ deploy_instructions.md
â”‚   â””â”€â”€ README_project.md
â”œâ”€â”€ capstone/
â”‚   â”œâ”€â”€ risk_model_pipeline/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ dashboard_project/
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â””â”€â”€ README.md
```

---

## ğŸ“¦ Module 1: Data Engineering & Foundations
- SQL (joins, subqueries, window functions)
- Pandas (cleaning, grouping, reshaping)
- File formats: CSV, JSON, Parquet
- Data modelling: star & snowflake
- Cloud basics: AWS S3, IAM roles

**âœ… Project:** Raw CSV â†’ Cleaned Parquet â†’ Upload to S3

---

## ğŸ” Module 2: Pipelines & Orchestration
- ETL/ELT workflows
- Airflow / Prefect DAG setup
- Scheduling, dependencies
- Logging + pipeline testing with pytest

**âœ… Project:** Airflow DAG with Python transformations + cloud integration

---

## ğŸ§± Module 3: Analytics Engineering & Warehousing
- dbt: cleaning and modelling layers
- BigQuery/Snowflake/Redshift basics
- Data warehouse optimisation (partitioning, indexing)
- Access control and cost management

**âœ… Project:** Build an analytics-ready warehouse model using dbt

---

## ğŸ¤– Module 4: Core Data Science & ML Principles
- *Data Science from Scratch* chapter-by-chapter builds
- Data exploration + preprocessing
- Implement linear regression, k-NN, Naive Bayes, trees from scratch
- Practice with scikit-learn for comparison
- Evaluation metrics and model validation

**âœ… Project:** Rebuild 3 ML models from scratch + notebook comparisons

---

## âš™ï¸ Module 5: Deployment & Capstone
- Version control (GitHub best practices)
- Docker + environment setup
- Deployment basics (script vs model vs dashboard)
- Logging, error monitoring, retry logic
- Portfolio polish

**âœ… Project:** Full ETL-to-ML pipeline or risk analysis dashboard, deployed and documented

---

## ğŸ Final Capstone Options
- **Risk Scoring System**
- **Data Quality Pipeline with Alerts**
- **Dashboard of Model Outputs from Clean Data Warehouse**
